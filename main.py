import streamlit as st
import speech_recognition as sr
from gtts import gTTS
import io
import numpy as np
from PIL import Image
import time

# Initialize the speech recognizer
recognizer = sr.Recognizer()

def text_to_speech_urdu(text):
    """Convert text to Urdu speech and play it using Streamlit"""
    try:
        tts = gTTS(text=text, lang='ur')
        audio_bytes = io.BytesIO()
        tts.write_to_fp(audio_bytes)
        audio_bytes.seek(0)
        st.audio(audio_bytes, format="audio/mp3")
    except Exception as e:
        st.error(f"Error in text-to-speech: {e}")

def speech_to_text():
    """Convert speech to text with improved handling and debugging"""
    with sr.Microphone() as source:
        st.write("Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ú†ÛŒÚ© ÛÙˆ Ø±ÛØ§ ÛÛ’... Ø¨Ø±Ø§Û Ú©Ø±Ù… ÛŒÙ‚ÛŒÙ†ÛŒ Ø¨Ù†Ø§Ø¦ÛŒÚº Ú©Û ÛŒÛ Ú©Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÛ’Û”")
        retries = 2
        for attempt in range(retries):
            try:
                audio_test = recognizer.listen(source, timeout=3)
                st.write("Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ú©Ø§Ù… Ú©Ø± Ø±ÛØ§ ÛÛ’Û” Ø§Ø¨ Ø³Ù†ÛŒÚº... Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¨ÙˆÙ„Ù†Ø§ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚºÛ”")
                break
            except sr.WaitTimeoutError:
                if attempt < retries - 1:
                    st.warning("Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ù¹ÛŒØ³Ù¹ Ù†Ø§Ú©Ø§Ù…Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛØ§ ÛÙˆÚº...")
                    text_to_speech_urdu("Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ù¹ÛŒØ³Ù¹ Ù†Ø§Ú©Ø§Ù…Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛØ§ ÛÙˆÚºÛ”")
                    time.sleep(1)
                else:
                    st.error("Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ù¹ÛŒØ³Ù¹ Ù†Ø§Ú©Ø§Ù… ÛÙˆ Ú¯ÛŒØ§Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø§Ù¾Ù†Ø§ Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”")
                    text_to_speech_urdu("Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ú©Ø§Ù… Ù†ÛÛŒÚº Ú©Ø± Ø±ÛØ§Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”")
                    return None

        # Adjust settings for better speech detection
        recognizer.energy_threshold = 300
        recognizer.adjust_for_ambient_noise(source, duration=1)
        recognizer.pause_threshold = 1.0
        st.write(f"Debug: Energy threshold set to {recognizer.energy_threshold}")
        st.write(f"Debug: Pause threshold set to {recognizer.pause_threshold}")

        st.write("Ø³ÙˆØ§Ù„ Ú©Û’ Ø¨Ø¹Ø¯ 2 Ø³ÛŒÚ©Ù†Úˆ Ø§Ù†ØªØ¸Ø§Ø± Ú©Ø±ÛŒÚº Ù¾Ú¾Ø± Ø¨ÙˆÙ„ÛŒÚºÛ”")
        time.sleep(2)

        listen_retries = 2
        for attempt in range(listen_retries):
            try:
                st.write(f"Ú©ÙˆØ´Ø´ {attempt + 1}: Ø¢ÙˆØ§Ø² Ø³Ù† Ø±ÛØ§ ÛÙˆÚº...")
                audio = recognizer.listen(source, timeout=20, phrase_time_limit=30)
                st.write("Debug: Ø¢ÙˆØ§Ø² Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ø³Û’ Ú©ÛŒÙ¾Ú†Ø± ÛÙˆØ¦ÛŒÛ” Ú¯ÙˆÚ¯Ù„ API Ú©Ùˆ Ø¨Ú¾ÛŒØ¬ Ø±ÛØ§ ÛÙˆÚº...")
                text = recognizer.recognize_google(audio, language='ur-PK')
                st.write(f"Debug: Ø´Ù†Ø§Ø®Øª Ø´Ø¯Û Ù…ØªÙ†: {text}")
                return text
            except sr.UnknownValueError:
                if attempt < listen_retries - 1:
                    st.warning("Ø¢ÙˆØ§Ø² Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢Ø¦ÛŒÛ” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚº... Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¨Ù„Ù†Ø¯ Ø¢ÙˆØ§Ø² Ù…ÛŒÚº Ø¨ÙˆÙ„ÛŒÚºÛ”")
                    text_to_speech_urdu("Ø¢ÙˆØ§Ø² Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢Ø¦ÛŒÛ” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”")
                    time.sleep(1)
                else:
                    st.error("Ø¢ÙˆØ§Ø² Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢Ø¦ÛŒÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… ØµØ§Ù Ø§ÙˆØ± Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¨ÙˆÙ„ÛŒÚºØŒ ÛŒØ§ Ø¯Ø³ØªÛŒ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚºÛ”")
                    text_to_speech_urdu("Ø¢ÙˆØ§Ø² Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢Ø¦ÛŒÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… ØµØ§Ù Ø§ÙˆØ± Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¨ÙˆÙ„ÛŒÚºÛ”")
                    return None
            except sr.RequestError as e:
                st.error(f"Ù†ØªÛŒØ¬Û Ø­Ø§ØµÙ„ Ù†ÛÛŒÚº ÛÙˆ Ø³Ú©Ø§Û” Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ú†ÛŒÚ© Ú©Ø±ÛŒÚº: {e}")
                text_to_speech_urdu("Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ú©Ù†Ú©Ø´Ù† Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”")
                return None
            except sr.WaitTimeoutError:
                if attempt < listen_retries - 1:
                    st.warning("Ø³Ù…Ø§Ø¹Øª Ú©Ø§ ÙˆÙ‚Øª Ø®ØªÙ… ÛÙˆ Ú¯ÛŒØ§Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚº...")
                    text_to_speech_urdu("Ø³Ù…Ø§Ø¹Øª Ú©Ø§ ÙˆÙ‚Øª Ø®ØªÙ… ÛÙˆ Ú¯ÛŒØ§Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”")
                    time.sleep(1)
                else:
                    st.error("Ø³Ù…Ø§Ø¹Øª Ú©Ø§ ÙˆÙ‚Øª Ø®ØªÙ… ÛÙˆ Ú¯ÛŒØ§Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… 20 Ø³ÛŒÚ©Ù†Úˆ Ú©Û’ Ø§Ù†Ø¯Ø± Ø¨ÙˆÙ„ÛŒÚº ÛŒØ§ Ø¯Ø³ØªÛŒ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚºÛ”")
                    text_to_speech_urdu("Ø³Ù…Ø§Ø¹Øª Ú©Ø§ ÙˆÙ‚Øª Ø®ØªÙ… ÛÙˆ Ú¯ÛŒØ§Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… 20 Ø³ÛŒÚ©Ù†Úˆ Ú©Û’ Ø§Ù†Ø¯Ø± Ø¨ÙˆÙ„ÛŒÚºÛ”")
                    return None
            except Exception as e:
                st.error(f"Error in speech-to-text: {e}")
                return None

def capture_photo():
    """Capture a photo using the webcam or upload a photo with validation"""
    st.write("Ø¢Ù¾ Ø§Ù¾Ù†ÛŒ ØªØµÙˆÛŒØ± Ø§Ù¾ Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº ÛŒØ§ Ú©ÛŒÙ…Ø±Û’ Ø³Û’ ØªØµÙˆÛŒØ± Ù„ÛŒÚº")
    captured_image = st.camera_input("ÙˆÛŒØ¨ Ú©ÛŒÙ… Ø³Û’ ØªØµÙˆÛŒØ± Ù„ÛŒÚº")
    if captured_image is not None:
        image = Image.open(captured_image)
        if image.size[0] > 2000 or image.size[1] > 2000:
            st.error("ØªØµÙˆÛŒØ± Ø¨ÛØª Ø¨Ú‘ÛŒ ÛÛ’Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… 2000x2000 Ù¾Ú©Ø³Ù„ Ø³Û’ Ú†Ú¾ÙˆÙ¹ÛŒ ØªØµÙˆÛŒØ± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚºÛ”")
            text_to_speech_urdu("ØªØµÙˆÛŒØ± Ø¨ÛØª Ø¨Ú‘ÛŒ ÛÛ’Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ú†Ú¾ÙˆÙ¹ÛŒ ØªØµÙˆÛŒØ± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚºÛ”")
            return None
        return np.array(image)

    uploaded_file = st.file_uploader("ÛŒØ§ ØªØµÙˆÛŒØ± Ø§Ù¾ Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        if image.size[0] > 2000 or image.size[1] > 2000:
            st.error("ØªØµÙˆÛŒØ± Ø¨ÛØª Ø¨Ú‘ÛŒ ÛÛ’Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… 2000x2000 Ù¾Ú©Ø³Ù„ Ø³Û’ Ú†Ú¾ÙˆÙ¹ÛŒ ØªØµÙˆÛŒØ± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚºÛ”")
            text_to_speech_urdu("ØªØµÙˆÛŒØ± Ø¨ÛØª Ø¨Ú‘ÛŒ ÛÛ’Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ú†Ú¾ÙˆÙ¹ÛŒ ØªØµÙˆÛŒØ± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚºÛ”")
            return None
        return np.array(image)

    return None

def convert_urdu_number(urdu_text):
    """Helper function to convert Urdu numbers to integers"""
    if not urdu_text:
        return None
    urdu_to_eng = {
        'Ø§ÛŒÚ©': 1, 'Ø¯Ùˆ': 2, 'ØªÛŒÙ†': 3, 'Ú†Ø§Ø±': 4, 'Ù¾Ø§Ù†Ú†': 5, 'Ú†Ú¾': 6, 'Ø³Ø§Øª': 7, 'Ø¢Ù¹Ú¾': 8, 'Ù†Ùˆ': 9, 'Ø¯Ø³': 10,
        'Ú¯ÛŒØ§Ø±Û': 11, 'Ø¨Ø§Ø±Û': 12, 'ØªÛŒØ±Û': 13, 'Ú†ÙˆØ¯Û': 14, 'Ù¾Ù†Ø¯Ø±Û': 15, 'Ø³ÙˆÙ„Û': 16, 'Ø³ØªØ±Û': 17, 'Ø§Ù¹Ú¾Ø§Ø±Û': 18,
        'Ø§Ù†ÛŒØ³': 19, 'Ø¨ÛŒØ³': 20, 'ØªÛŒØ³': 30, 'Ú†Ø§Ù„ÛŒØ³': 40, 'Ù¾Ú†Ø§Ø³': 50, 'Ø³Ø§Ù¹Ú¾': 60
    }
    urdu_text = urdu_text.strip()
    if urdu_text.isdigit():
        return int(urdu_text)
    return urdu_to_eng.get(urdu_text, None)

def ask_question(prompt, step_key, next_step, validate_func=None, error_msg=None, success_msg=None):
    """Helper function to handle voice/manual input for a question"""
    st.write(prompt)
    if st.button("Ø¨ÙˆÙ„ÛŒÚº (Speak)", key=f"speak_{step_key}"):
        response = speech_to_text()
        if response:
            st.write(f"Ø´Ù†Ø§Ø®Øª Ø´Ø¯Û Ø¬ÙˆØ§Ø¨: {response}")
            if validate_func:
                validated_response = validate_func(response)
                if validated_response is None:
                    st.error(error_msg)
                    text_to_speech_urdu(error_msg)
                    return
                response = validated_response
            st.session_state.responses[step_key] = response
            if success_msg:
                st.success(success_msg.format(response))
            st.session_state.step = next_step
            return response
    if st.button("Ø¯Ø³ØªÛŒ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº (Enter Manually)", key=f"manual_{step_key}"):
        if step_key == 'age':
            response = st.number_input("Ø¹Ù…Ø± Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº", min_value=1, max_value=60, key=f"manual_{step_key}_input")
        else:
            response = st.text_input(f"{prompt} Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº", key=f"manual_{step_key}_input")
        if response:
            if validate_func:
                validated_response = validate_func(str(response))
                if validated_response is None:
                    st.error(error_msg)
                    text_to_speech_urdu(error_msg)
                    return
                response = validated_response
            st.session_state.responses[step_key] = response
            if success_msg:
                st.success(success_msg.format(response))
            st.session_state.step = next_step
            return response

def main():
    # Page configuration
    st.set_page_config(page_title="Ø§Ø±Ø¯Ùˆ ÙˆØ§Ø¦Ø³ Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù† ÙØ§Ø±Ù…", page_icon="ğŸ™ï¸")
    st.title("Ø§Ø±Ø¯Ùˆ ÙˆØ§Ø¦Ø³ Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù† ÙØ§Ø±Ù…")
    st.subheader("Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù† ÙØ§Ø±Ù… - ÙˆØ§Ø¦Ø³ Ø§Ù† Ù¾Ù¹ Ú©Û’ Ø³Ø§ØªÚ¾")

    # Initialize session state
    if 'step' not in st.session_state:
        st.session_state.step = 0
        st.session_state.responses = {}

    # Step 0: Start
    if st.session_state.step == 0:
        if st.button("Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº (Start)"):
            text_to_speech_urdu("Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ")
            st.session_state.step = 1

    # Step 1: Name
    elif st.session_state.step == 1:
        ask_question("Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ", "name", 2, success_msg="Ù†Ø§Ù… Ù…Ø­ÙÙˆØ¸ ÛÙˆ Ú¯ÛŒØ§: {}")
        if st.session_state.step == 2:
            text_to_speech_urdu("Ø¢Ù¾ Ú©ÛŒ Ø¹Ù…Ø± Ú©ÛŒØ§ ÛÛ’ØŸ")

    # Step 2: Age
    elif st.session_state.step == 2:
        def validate_age(age_text):
            age = convert_urdu_number(age_text)
            if age is None:
                return None
            if age > 60:
                st.error("Ù…Ø¹Ø°Ø±ØªØŒ Ø¢Ù¾ Ú©ÛŒ Ø¹Ù…Ø± Ø²ÛŒØ§Ø¯Û ÛÛ’")
                text_to_speech_urdu("Ù…Ø¹Ø°Ø±ØªØŒ Ø¢Ù¾ Ú©ÛŒ Ø¹Ù…Ø± Ø²ÛŒØ§Ø¯Û ÛÛ’")
                st.session_state.step = 0
                st.session_state.responses = {}
                return None
            return age

        ask_question("Ø¢Ù¾ Ú©ÛŒ Ø¹Ù…Ø± Ú©ÛŒØ§ ÛÛ’ØŸ", "age", 3, validate_age, "Ø¹Ù…Ø± Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢Ø¦ÛŒÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”", "Ø¹Ù…Ø± Ù…Ø­ÙÙˆØ¸ ÛÙˆ Ú¯Ø¦ÛŒ: {}")
        if st.session_state.step == 3:
            text_to_speech_urdu("Ø¢Ù¾ Ú©ÛŒ Ø¬Ù†Ø³ Ú©ÛŒØ§ ÛÛ’ØŸ")

    # Step 3: Gender
    elif st.session_state.step == 3:
        def validate_gender(gender_text):
            gender_text = gender_text.strip().lower()
            if gender_text in ["Ù…Ø±Ø¯", "Ø¹ÙˆØ±Øª", "male", "female"]:
                return gender_text
            return None

        ask_question("Ø¢Ù¾ Ú©ÛŒ Ø¬Ù†Ø³ Ú©ÛŒØ§ ÛÛ’ØŸ (Ù…Ø±Ø¯/Ø¹ÙˆØ±Øª)", "gender", 4, validate_gender, "Ø¬Ù†Ø³ Ø³Ù…Ø¬Ú¾ Ù†ÛÛŒÚº Ø¢Ø¦ÛŒÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… 'Ù…Ø±Ø¯' ÛŒØ§ 'Ø¹ÙˆØ±Øª' Ø¨ÙˆÙ„ÛŒÚºÛ”", "Ø¬Ù†Ø³ Ù…Ø­ÙÙˆØ¸ ÛÙˆ Ú¯Ø¦ÛŒ: {}")
        if st.session_state.step == 4:
            text_to_speech_urdu("Ø¢Ù¾ Ú©Û’ Ø³Ø±Ø¨Ø±Ø§Û Ú©Ø§ Ø´Ù†Ø§Ø®ØªÛŒ Ú©Ø§Ø±Úˆ Ù†Ù…Ø¨Ø± Ú©ÛŒØ§ ÛÛ’ØŸ")

    # Step 4: NIC
    elif st.session_state.step == 4:
        st.write("Ø¢Ù¾ Ú©Û’ Ø³Ø±Ø¨Ø±Ø§Û Ú©Ø§ Ø´Ù†Ø§Ø®ØªÛŒ Ú©Ø§Ø±Úˆ Ù†Ù…Ø¨Ø± Ú©ÛŒØ§ ÛÛ’ØŸ")
        nic = st.text_input("Ø´Ù†Ø§Ø®ØªÛŒ Ú©Ø§Ø±Úˆ Ù†Ù…Ø¨Ø± Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº (13 ÛÙ†Ø¯Ø³ÙˆÚº Ú©Ø§)", key="nic")
        if st.button("Ø§Ú¯Ù„Ø§ (Next)", key="nic_next_button"):
            if len(nic) == 13 and nic.isdigit():
                st.session_state.responses['nic'] = nic
                st.session_state.step = 5
                text_to_speech_urdu("Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø§Ù¾Ù†ÛŒ ØªØµÙˆÛŒØ± Ø§Ù¾ Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº ÛŒØ§ Ú©ÛŒÙ…Ø±Û’ Ø³Û’ ØªØµÙˆÛŒØ± Ù„ÛŒÚº")
            else:
                st.error("Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯Ø±Ø³Øª Ø´Ù†Ø§Ø®ØªÛŒ Ú©Ø§Ø±Úˆ Ù†Ù…Ø¨Ø± Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº (13 ÛÙ†Ø¯Ø³ÙˆÚº Ú©Ø§)")
                text_to_speech_urdu("Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯Ø±Ø³Øª Ø´Ù†Ø§Ø®ØªÛŒ Ú©Ø§Ø±Úˆ Ù†Ù…Ø¨Ø± Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº")

    # Step 5: Photo
    elif st.session_state.step == 5:
        photo = capture_photo()
        if photo is not None:
            st.image(photo, caption="Ø¢Ù¾ Ú©ÛŒ ØªØµÙˆÛŒØ±")
            st.session_state.responses['photo'] = photo
            st.session_state.step = 6

    # Step 6: Submission
    elif st.session_state.step == 6:
        st.success("Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù† Ù…Ú©Ù…Ù„ ÛÙˆ Ú¯Ø¦ÛŒ!")
        text_to_speech_urdu("Ø¢Ù¾ Ú©ÛŒ Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù† Ù…Ú©Ù…Ù„ ÛÙˆ Ú¯Ø¦ÛŒ ÛÛ’Û” Ø´Ú©Ø±ÛŒÛ")
        st.write("### Ø¬Ù…Ø¹ Ø´Ø¯Û Ù…Ø¹Ù„ÙˆÙ…Ø§Øª:")
        for key, value in st.session_state.responses.items():
            if key != 'photo':
                st.write(f"{key}: {value}")
        if 'photo' in st.session_state.responses:
            st.image(st.session_state.responses['photo'], caption="Ø¬Ù…Ø¹ Ø´Ø¯Û ØªØµÙˆÛŒØ±")

        if st.button("Ù†Ø¦ÛŒ Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù† (New Registration)"):
            st.session_state.step = 0
            st.session_state.responses = {}

if __name__ == "__main__":
    main()